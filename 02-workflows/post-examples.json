[
  {
    "topic": "Open LLMs are great because they are more than enough for many workflows and offer free use & 100% privacy!",
    "post": "Yes, Gemini 2.5 Pro is amazing. But for many tasks, it's too expensive & simply overkill.\n\nDon't sleep on open LLMs which you can run locally on your MacBook!\n\nOpen LLMs like Gemma 3 can be run locally via Ollama or LM Studio, offer 100% privacy and are more than capable enough for most use-cases and workflows."
  },
  {
    "topic": "Despite LLms: Learn to code! Because AI-assisted coding > Vibe coding.",
    "post": "There's never been a better time to learn coding! Seriously!\n\nYes, you can vibe code sloppy apps all day.\n\nIf you want to build something that acctually works, you need to learn to code though.\n\nCombine that with AI assistants like Copilot and nothing's going to stop you!"
  }
]
